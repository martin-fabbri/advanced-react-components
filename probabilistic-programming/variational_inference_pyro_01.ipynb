{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "variational-inference-pyro-01.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPc26G+thKYiddDL/E5xqDQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martin-fabbri/advanced-react-components/blob/master/probabilistic-programming/variational_inference_pyro_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7jBl07iPtiJ",
        "colab_type": "text"
      },
      "source": [
        "# Variational Inference Pyro"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6rsB9IqQUXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q pyro-ppl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZDWXWc8QcPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import os\n",
        "import torch\n",
        "import torch.distributions.constraints as constraints\n",
        "import pyro\n",
        "from pyro.optim import Adam\n",
        "from pyro.infer import SVI\n",
        "from pyro.infer import Trace_ELBO\n",
        "from pyro.distributions import Beta\n",
        "from pyro.distributions import Bernoulli"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xb58nIfLqkJH",
        "colab_type": "text"
      },
      "source": [
        "Symbol | Represents\n",
        ":---:|---\n",
        "$$\\mathbf{z}$$\t| The compressed code learned in the bottleneck layer\n",
        "$$q_{\\phi}(\\mathbf{z}\\vert\\mathbf{x})$$\t| Estimated posterior probability function\n",
        "$$p_{\\theta}(\\mathbf{x}\\vert\\mathbf{z})$$ |\tLikelihood of generating true data sample given the latent code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNqn7FE6Pte_",
        "colab_type": "text"
      },
      "source": [
        "$$p_0(x, z) = p_o(x|z)p_0(z)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IS1zJgcPtbt",
        "colab_type": "text"
      },
      "source": [
        "## Model\n",
        "\n",
        "Learning a good model will be maximixing the log evidence:\n",
        "\n",
        "$$\\theta_\\max=\\underset{\\theta}{argmax}\\;{log\\;p_0(x)}$$\n",
        "\n",
        "where the log evidence $log\\;p_{\\theta}(x)$ is given by:\n",
        "\n",
        "$$ log\\;p_0(x) = log \\int{dz\\;p_{\\theta}(x,z)} $$\n",
        "\n",
        "Solving the integral over the latent random variable $\\bf z$ is often intractable.  \n",
        "\n",
        "In addition to finding $\\theta_{\\rm{max}}$, we would like to calculate the posterior over the latent variables $\\bf z$:\n",
        "\n",
        "$$ p_{\\theta_{\\rm{max}}}({\\bf z} | {\\bf x}) = \\frac{p_{\\theta_{\\rm{max}}}({\\bf x} , {\\bf z})}{\n",
        "\\int \\! d{\\bf z}\\; p_{\\theta_{\\rm{max}}}({\\bf x} , {\\bf z}) } $$\n",
        "\n",
        "Note that the denominator of this expression is the (usually intractable) evidence. Variational inference offers a scheme for finding $\\theta_{\\rm{max}}$ and computing an approximation to the posterior $p_{\\theta_{\\rm{max}}}({\\bf z} | {\\bf x})$. Let's see how that works."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NY7qYlUyPtYc",
        "colab_type": "text"
      },
      "source": [
        "## Guide\n",
        "\n",
        "The basic idea is that we introduce a parameterized distribution $q_{\\phi}({\\bf z})$, where $\\phi$ are known as the variational parameters. This distribution is called the variational distribution in much of the literature, and in the context of Pyro it's called the **guide** (one syllable instead of nine!). The guide will serve as an approximation to the posterior.\n",
        "\n",
        "> Note that **guide** does _not_ contain observed data, since the guide needs to be a properly normalized distribution.\n",
        "\n",
        "FIX ME: Recall that when random variables are specified in Pyro with the primitive statement `pyro.sample()` the first argument denotes the name of the random variable. These names will be used to align the random variables in the model and guide. To be very explicit, if the model contains a random variable `z_1`\n",
        "\n",
        "```python\n",
        "def model():\n",
        "    pyro.sample(\"z_1\", ...)\n",
        "```\n",
        "\n",
        "then the guide needs to have a matching `sample` statement\n",
        "\n",
        "```python\n",
        "def guide():\n",
        "    pyro.sample(\"z_1\", ...)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWA3CZnlzwTN",
        "colab_type": "text"
      },
      "source": [
        "## ELBO\n",
        "\n",
        "Evidence lower bound (ELBO) is a function of both $\\theta$ and $\\phi$ defined as an expectation w.r.t. to samples from the **guide**:\n",
        "\n",
        "$${\\rm ELBO} \\equiv \\mathbb{E}_{q_{\\phi}({\\bf z})} \\left [ \n",
        "\\log p_{\\theta}({\\bf x}, {\\bf z}) - \\log q_{\\phi}({\\bf z})\n",
        "\\right]$$\n",
        "\n",
        "By assumption we can compute the log probabilities inside the expectation. And since the guide is assumed to be a parametric distribution we can sample from, we can compute Monte Carlo estimates of this quantity. Crucially, the ELBO is a lower bound to the log evidence, i.e. for all choices of $\\theta$ and $\\phi$ we have that \n",
        "\n",
        "$$\\log p_{\\theta}({\\bf x}) \\ge {\\rm ELBO} $$\n",
        "\n",
        "So if we take (stochastic) gradient steps to maximize the ELBO, we will also be pushing the log evidence higher (in expectation). Furthermore, it can be shown that the gap between the ELBO and the log evidence is given by the KL divergence between the guide and the posterior:\n",
        "\n",
        "$$ \\log p_{\\theta}({\\bf x}) - {\\rm ELBO} = \n",
        "\\rm{KL}\\!\\left( q_{\\phi}({\\bf z}) \\lVert p_{\\theta}({\\bf z} | {\\bf x}) \\right) $$\n",
        "\n",
        "This KL divergence is a particular (non-negative) measure of 'closeness' between two distributions. So, for a fixed $\\theta$, as we take steps in $\\phi$ space that increase the ELBO, we decrease the KL divergence between the guide and the posterior, i.e. we move the guide towards the posterior. In the general case we take gradient steps in both $\\theta$ and $\\phi$ space simultaneously so that the guide and model play chase, with the guide tracking a moving posterior $\\log p_{\\theta}({\\bf z} | {\\bf x})$. Perhaps somewhat surprisingly, despite the moving target, this optimization problem can be solved (to a suitable level of approximation) for many different problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qG3AfF6oOmqW",
        "colab_type": "text"
      },
      "source": [
        "## Sample\n",
        "\n",
        "You've been given a two-sided coin. You want to determine whether the coin is fair or not, i.e. whether it falls heads or tails with the same frequency. You have a prior belief about the likely fairness of the coin based on two observations:\n",
        "\n",
        "- it's a standard quarter issued by the US Mint\n",
        "- it's a bit banged up from years of use\n",
        "\n",
        "So while you expect the coin to have been quite fair when it was first produced, you allow for its fairness to have since deviated from a perfect 1:1 ratio. So you wouldn't be surprised if it turned out that the coin preferred heads over tails at a ratio of 11:10. By contrast you would be very surprised if it turned out that the coin preferred heads over tails at a ratio of 5:1—it's not that banged up.\n",
        "\n",
        "To turn this into a probabilistic model we encode heads and tails as 1s and 0s. We encode the fairness of the coin as a real number  f , where  f  satisfies  f∈[0.0,1.0]  and  f=0.50  corresponds to a perfectly fair coin. Our prior belief about  f  will be encoded by a beta distribution, specifically  Beta(10,10) , which is a symmetric probability distribution on the interval  [0.0,1.0]  that is peaked at  f=0.5 ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40g5e_U5zv9q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3f4124a3-24e1-4585-ba5d-fb0257ac31ef"
      },
      "source": [
        "n_steps = 2000\n",
        "pyro.enable_validation(True)\n",
        "\n",
        "pyro.clear_param_store()\n",
        "\n",
        "data = []\n",
        "for _ in range(6):\n",
        "  data.append(torch.tensor(1.0))\n",
        "\n",
        "for _ in range(4):\n",
        "  data.append(torch.tensor(0.0))\n",
        "\n",
        "def model(data):\n",
        "  alpha0 = torch.tensor(10.0)\n",
        "  beta0 = torch.tensor(10.0)\n",
        "\n",
        "  # sample f from the beta prior\n",
        "  f = pyro.sample('latent_fairness', Beta(alpha0, beta0))\n",
        "  for i in range(len(data)):\n",
        "    pyro.sample(f'obs_{i}', Bernoulli(f), obs=data[i])\n",
        "\n",
        "def guide(data):\n",
        "  # register the two variational parameter with Pyro\n",
        "  # - both parameters will have initial value 15.0\n",
        "  # - because we invoke constraints.positive, the optimizer will\n",
        "  #   take the gradients on the unconstrained parameters\n",
        "  #   (which are related to the constrained parameters by a log)\n",
        "  alpha_q = pyro.param('alpha_q', torch.tensor(15.0), \n",
        "                       constraint=constraints.positive)\n",
        "  beta_q = pyro.param('beta_q', torch.tensor(15.0),\n",
        "                      constraint=constraints.positive)\n",
        "  pyro.sample('latent_fairness', Beta(alpha_q, beta_q))\n",
        "\n",
        "adam_params = {'lr': 0.0005, 'betas': (0.90, 0.999)}\n",
        "optimizer = Adam(adam_params)\n",
        "\n",
        "svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
        "\n",
        "for step in range(n_steps):\n",
        "  svi.step(data)\n",
        "  if step % 100 == 0:\n",
        "    print('.', end='')\n",
        "\n",
        "# grag the learned variational parameters\n",
        "alpha_q = pyro.param('alpha_q').item()\n",
        "beta_q = pyro.param('beta_q').item()\n",
        "\n",
        "# here we use some facts about the beta distribution\n",
        "# compute the inferred mean of the coin's fairness\n",
        "inferred_mean = alpha_q / (alpha_q + beta_q)\n",
        "\n",
        "factor = beta_q / (alpha_q * (1.0 + alpha_q + beta_q))\n",
        "inferred_std = inferred_mean * math.sqrt(factor)\n",
        "\n",
        "print(f'\\nbased on the data and our prior belief, the fairness of the coin is {inferred_mean:.3f} +- {inferred_std:.3f}')\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "....................\n",
            "based on the data and our prior belief, the fairness of the coin is 0.540 +- 0.090\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}